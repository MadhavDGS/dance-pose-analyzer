# Demo Video Script - API Usage Guide

## ðŸŽ¥ 2-Minute Demo Video Script for Callus Assignment

### **Timeline Breakdown:**
- [0:00-0:15] Introduction & Code Overview (15 sec)
- [0:15-0:45] Technical Decisions Explanation (30 sec)
- [0:45-1:45] Live API Demo (60 sec)
- [1:45-2:00] Results & Conclusion (15 sec)

---

## ðŸ“ SCRIPT

### [0:00-0:15] Introduction (15 seconds)

**Screen: VS Code with project open**

> "Hi, I'm Sree Madhav. This is my Dance Pose Analyzer for Callus's AI/ML Engineer position. 
> 
> [Quickly show file tree in VS Code]
> 
> The system uses MediaPipe for pose detection, FastAPI for the REST API, and Docker for deployment. Let me show you how it works."

**What to show:**
- Quick pan through project structure in VS Code
- Highlight: `src/pose_detector.py`, `src/api.py`, `Dockerfile`

---

### [0:15-0:45] Technical Decisions (30 seconds)

**Screen: Show `pose_detector.py` briefly**

> "I chose MediaPipe over OpenPose because it's 4-6 times fasterâ€”processing at 30 milliseconds per frame on CPUâ€”while maintaining 97% accuracy.
>
> FastAPI provides async support for handling multiple video uploads and generates automatic API documentation.
>
> The system uses model complexity 1, which balances speed and accuracy perfectly for cloud deployment without GPUs.
>
> Docker containerization ensures consistent deployment across any cloud platform."

**What to show:**
- Briefly show the `PoseDetector` class initialization
- Point to `model_complexity=1` line
- Show Dockerfile briefly

---

### [0:45-1:45] Live API Demo (60 seconds) - **MAIN SECTION**

**Screen: Open deployed URL in browser (or localhost if not deployed yet)**

#### Step 1: Show API Documentation (10 sec)
> "The API is deployed at [YOUR-URL]. Let me open the interactive documentation."

**Actions:**
1. Open browser to: `https://your-deployed-url/docs` (or `http://localhost:8000/docs`)
2. Show the Swagger UI with all endpoints visible

#### Step 2: Upload Video (25 sec)
> "I'll upload a dance video using the POST /api/analyze endpoint. 
> 
> [Click on POST /api/analyze â†’ Try it out]
> 
> I'll select a test video... 
> 
> [Choose file, click Execute]
> 
> And execute. The API processes the video frame-by-frame, detecting 33 body landmarks in each frame using MediaPipe."

**Actions:**
1. Click **POST /api/analyze**
2. Click **"Try it out"**
3. Click **"Choose File"** and select your test dance video
4. Click **"Execute"**
5. Wait for response (should take 5-10 seconds)

#### Step 3: Show Response (15 sec)
> "Great! The response shows 100% pose detection rate across 217 frames. 
> 
> [Point to the response JSON]
> 
> Here's the video ID and download URL. Let me copy this download link."

**Actions:**
1. Scroll to Response Body
2. Point out key fields:
   - `"video_id"`
   - `"status": "completed"`
   - `"Pose detected in X frames (100%)"`
   - `"download"` â†’ `"direct_link"`
3. Copy the `direct_link` URL

#### Step 4: Download and Show Result (10 sec)
> "I'll paste the download URL in a new tab to get the processed video."

**Actions:**
1. Open new browser tab
2. Paste the download URL
3. Video downloads automatically
4. Open the downloaded video

---

### [1:45-2:00] Results & Conclusion (15 seconds)

**Screen: Playing the processed video with skeleton overlay**

> "As you can see, MediaPipe detected all body landmarks and rendered the skeleton overlay in real-time. 
>
> The system achieves 97% confidence scores, processes videos at 20-30 FPS on CPU, and is ready to scale for Callus's global creator platform.
>
> The code is on GitHub, deployed to [platform], with full documentation and 18 passing unit tests. Thank you!"

**What to show:**
- Processed video playing with visible skeleton overlay
- Briefly flash back to GitHub repo URL on screen

---

## ðŸŽ¬ RECORDING TIPS

### Before Recording:
1. **Clear your browser bookmarks bar** (remove personal bookmarks)
2. **Close unnecessary browser tabs**
3. **Increase browser zoom to 125%** (easier to see in video)
4. **Have your test video ready** (5-10 second dance clip works best)
5. **Test the upload once** to ensure API is working
6. **Restart the API** before recording for clean logs

### During Recording:
1. **Speak clearly and at moderate pace**
2. **Don't rush the demo** - 2 minutes is enough time
3. **If you make a mistake**, just pause, wait 3 seconds, and start that section again (you can edit later)
4. **Show mouse cursor** so viewers can follow actions
5. **Wait for API responses** - silence during processing is OK

### Screen Recording Setup (macOS):
```bash
# QuickTime method:
1. Open QuickTime Player
2. File â†’ New Screen Recording
3. Click red record button
4. Select area (drag to select just browser + terminal if needed)
5. Click "Start Recording"

# Or use built-in screenshot tool:
1. Press Cmd+Shift+5
2. Select "Record Selected Portion" or "Record Entire Screen"
3. Click "Record"
```

### After Recording:
1. Trim any dead space at start/end
2. Add text overlay with your name and GitHub URL (optional)
3. Export as MP4
4. Upload to YouTube (unlisted) or Google Drive (public link)

---

## ðŸ“‹ QUICK REFERENCE CHECKLIST

**Before Starting:**
- [ ] API is running (deployed or localhost)
- [ ] Browser open to `/docs` endpoint
- [ ] Test video file ready (5-10 seconds, clear dancer)
- [ ] Screen recording tool ready
- [ ] Browser zoom at 125%
- [ ] Close unnecessary tabs/windows

**During Demo:**
- [ ] Introduce yourself and project (15 sec)
- [ ] Explain technical choices (30 sec)
- [ ] Open Swagger UI and show endpoints
- [ ] Upload video via POST /api/analyze
- [ ] Show response with video_id and detection rate
- [ ] Download processed video using direct_link
- [ ] Play processed video showing skeleton overlay
- [ ] Mention GitHub, deployment, tests (15 sec)

**URLs to Mention:**
- GitHub: `https://github.com/YOUR_USERNAME/dance-pose-analyzer`
- Deployed API: `https://your-app.railway.app` (or your actual URL)
- API Docs: `https://your-app.railway.app/docs`

---

## ðŸ’¡ ALTERNATIVE: If Not Deployed Yet

If you're recording before deployment, use `localhost:8000`:

> "The API is running locally at localhost:8000 for this demo, but it's fully containerized with Docker and ready for cloud deployment to Railway or Render."

Then at the end:
> "As shown in the README, deployment is simple: push to GitHub, connect to Railway, and the Dockerfile automatically handles the rest."

---

## ðŸŽ¯ KEY POINTS TO EMPHASIZE

1. **Speed**: "30 milliseconds per frame on CPU"
2. **Accuracy**: "97% confidence, 100% detection rate"
3. **Scalability**: "Async FastAPI handles multiple concurrent uploads"
4. **Production-ready**: "Docker containerized, 18 passing tests"
5. **Cloud-optimized**: "Runs efficiently on CPU, no GPU needed"

Good luck with your recording! ðŸš€
